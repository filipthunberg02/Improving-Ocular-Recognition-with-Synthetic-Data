{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Not connected to a GPU')\n",
        "else:\n",
        "  print(gpu_info)"
      ],
      "metadata": {
        "collapsed": true,
        "id": "S9-0gVEaiSMO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Install required packages\n",
        "!pip install -U insightface onnxruntime-gpu onnx opencv-python rarfile\n",
        "!apt-get install -y unrar\n",
        "\n",
        "# Imports\n",
        "import os\n",
        "import shutil\n",
        "import glob\n",
        "import cv2\n",
        "import numpy as np\n",
        "import onnx\n",
        "import onnxruntime as ort\n",
        "import rarfile\n",
        "from pathlib import Path\n",
        "from google.colab import drive\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "I6_XWOpMWTvI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Trimming of model\n",
        "\n",
        "import onnx.helper, onnx.shape_inference\n",
        "\n",
        "orig_model    = \"\" # Original ONNX file\n",
        "trimmed_model = \"\" # Trimmed model\n",
        "output_tensor = \"avg_pool\"\n",
        "\n",
        "# 1) Load, remove existing outputs, add avg_pool as only output\n",
        "model = onnx.load(orig_model)\n",
        "while len(model.graph.output) > 0:\n",
        "    model.graph.output.pop()\n",
        "model.graph.output.extend([onnx.helper.ValueInfoProto(name=output_tensor)])\n",
        "model = onnx.shape_inference.infer_shapes(model)\n",
        "onnx.save(model, trimmed_model)\n",
        "print(f\"Trimmed model saved → {trimmed_model}\")\n",
        "\n",
        "# 2) Launch ONNX Runtime session\n",
        "sess = ort.InferenceSession(\n",
        "    trimmed_model,\n",
        "    providers=[\"CUDAExecutionProvider\",\"CPUExecutionProvider\"]\n",
        ")\n",
        "inp = sess.get_inputs()[0]\n",
        "input_name = inp.name\n",
        "_, _, H, W = inp.shape\n",
        "print(f\"Session ready: input='{input_name}', size={H}×{W}\")\n"
      ],
      "metadata": {
        "id": "A_YLqOyroyWT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1) Mount Google Drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "# 2) Define and reset workspace folders\n",
        "BASE    = \"face_recognition_data\"\n",
        "GALLERY = os.path.join(BASE, \"gallery\")\n",
        "PROBE   = os.path.join(BASE, \"probe\")\n",
        "VERIF   = os.path.join(BASE, \"verification\")\n",
        "TEMP    = \"temp_extracted\"\n",
        "\n",
        "for p in [GALLERY, PROBE, VERIF, TEMP]:\n",
        "    if os.path.exists(p):\n",
        "        shutil.rmtree(p)\n",
        "os.makedirs(GALLERY)\n",
        "os.makedirs(PROBE)\n",
        "os.makedirs(VERIF)\n",
        "os.makedirs(TEMP)\n"
      ],
      "metadata": {
        "id": "YhG6LHsAm5f8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rar_path = \"\" # Path to your RAR on Drive\n",
        "\n",
        "# Clear & recreate TEMP\n",
        "if os.path.exists(TEMP):\n",
        "    shutil.rmtree(TEMP)\n",
        "os.makedirs(TEMP, exist_ok=True)\n",
        "\n",
        "# Extract everything\n",
        "with rarfile.RarFile(rar_path) as rf:\n",
        "    rf.extractall(TEMP)\n",
        "\n",
        "print(\"Extracted all images to\", TEMP)\n"
      ],
      "metadata": {
        "id": "PdTw7DP91aG1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_emb(img):\n",
        "    rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB).astype(\"float32\")\n",
        "    rgb = cv2.resize(rgb, (W, H)).transpose(2,0,1)[None]\n",
        "    out = sess.run(None, {input_name: rgb})[0].squeeze()\n",
        "    return out / np.linalg.norm(out)\n",
        "\n",
        "# Walk TEMP, extract embeddings\n",
        "records = []\n",
        "exts = {\".jpg\", \".jpeg\", \".png\", \".bmp\", \".tiff\"}\n",
        "\n",
        "for root, _, files in os.walk(TEMP):\n",
        "    identity = os.path.basename(root)\n",
        "    for fname in files:\n",
        "        if Path(fname).suffix.lower() in exts:\n",
        "            fp = os.path.join(root, fname)\n",
        "            img = cv2.imread(fp)\n",
        "            if img is None:\n",
        "                continue\n",
        "            emb = get_emb(img)\n",
        "            records.append({\"id\": identity, \"path\": fp, \"emb\": emb})\n",
        "\n",
        "print(f\"Computed embeddings for {len(records)} images from {len(set(r['id'] for r in records))} identities.\")\n"
      ],
      "metadata": {
        "id": "KPelsygcmZjK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gallery_embs = {}\n",
        "probe_embs   = {}\n",
        "verif_embs   = {}\n",
        "by_id        = {}\n",
        "\n",
        "# Group by identity\n",
        "for r in records:\n",
        "    by_id.setdefault(r[\"id\"], []).append(r)\n",
        "\n",
        "for id_, recs in by_id.items():\n",
        "    # 1) Sort once\n",
        "    recs_sorted = sorted(recs, key=lambda x: x[\"path\"])\n",
        "\n",
        "    # 2) Compute split point\n",
        "    half = len(recs_sorted) // 2\n",
        "\n",
        "    # 3) First half → gallery, also add to verification\n",
        "    for idx, r in enumerate(recs_sorted[:half]):\n",
        "        name = f\"{id_}_{idx}\"\n",
        "        emb  = r[\"emb\"]\n",
        "        gallery_embs[name] = emb\n",
        "        verif_embs[name]  = emb\n",
        "\n",
        "    # 4) Second half → probe, also add to verification\n",
        "    for idx, r in enumerate(recs_sorted[half:], start=half):\n",
        "        name = f\"{id_}_{idx}\"\n",
        "        emb  = r[\"emb\"]\n",
        "        probe_embs[name]  = emb\n",
        "        verif_embs[name]  = emb\n",
        "\n",
        "\n",
        "print(f\"Gallery: {len(gallery_embs)}, Probe: {len(probe_embs)}, Verification: {len(verif_embs)}\")\n"
      ],
      "metadata": {
        "id": "bsoRN9bOnHnt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Identification\n",
        "\n",
        "# Create lists of labels and embedding matrices\n",
        "gallery_labels = list(gallery_embs)\n",
        "gallery_matrix = np.vstack([gallery_embs[label] for label in gallery_labels])\n",
        "\n",
        "probe_labels = list(probe_embs)\n",
        "probe_matrix = np.vstack([probe_embs[label] for label in probe_labels])\n",
        "\n",
        "# Compute the similarity matrix between probe and gallery embeddings\n",
        "similarity_matrix = probe_matrix.dot(gallery_matrix.T)\n",
        "\n",
        "# Find the index of the most similar gallery embedding for each probe\n",
        "best_match_indices = similarity_matrix.argmax(axis=1)\n",
        "\n",
        "correct_matches = 0\n",
        "\n",
        "# Compare the predicted gallery identity with the probe identity\n",
        "for i, probe_label in enumerate(probe_labels):\n",
        "    best_gallery_label = gallery_labels[best_match_indices[i]]\n",
        "    similarity_score = similarity_matrix[i, best_match_indices[i]]\n",
        "\n",
        "    # Check if the probe and gallery have the same identity (based on the label)\n",
        "    if probe_label.split(\"_\")[0] == best_gallery_label.split(\"_\")[0]:\n",
        "        correct_matches += 1\n",
        "        print(f\"Correct: {probe_label} → {best_gallery_label} ({similarity_score:.4f})\")\n",
        "    else:\n",
        "        print(f\"Incorrect: {probe_label} → {best_gallery_label} ({similarity_score:.4f})\")\n",
        "\n",
        "# Calculate identification accuracy\n",
        "accuracy = (correct_matches / len(probe_labels)) * 100\n",
        "print(f\"\\nRank-1 Rate: {accuracy:.2f}%\")"
      ],
      "metadata": {
        "id": "BHNujsrKnJNA",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creation of genuine and imposter pairs\n",
        "\n",
        "# Build genuine and impostor pairs\n",
        "pairs = []\n",
        "# ids = sorted(by_id)\n",
        "# Genuine pairs\n",
        "for identity, images in by_id.items():\n",
        "    for i in range(len(images)):\n",
        "        for j in range(i + 1, len(images)):\n",
        "            pairs.append((images[i][\"emb\"], images[j][\"emb\"], 0))\n",
        "\n",
        "# Impostor pairs\n",
        "identities = sorted(by_id)\n",
        "for i in range(len(identities)):\n",
        "    for j in range(i + 1, len(identities)):\n",
        "        for img1 in by_id[identities[i]]:\n",
        "            for img2 in by_id[identities[j]]:\n",
        "                pairs.append((img1[\"emb\"], img2[\"emb\"], 1))\n",
        "\n",
        "\n",
        "# Count and print how many of each\n",
        "num_genuine  = sum(1 for *_, lbl in pairs if lbl == 0)\n",
        "num_imposter = sum(1 for *_, lbl in pairs if lbl == 1)\n",
        "print(f\"Total genuine pairs:  {num_genuine}\")\n",
        "print(f\"Total impostor pairs: {num_imposter}\\n\")"
      ],
      "metadata": {
        "id": "-fmn-cjlNreU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check for FAR and FRR at chosen threshold\n",
        "\n",
        "threshold = 0.5 # Chosen threshold\n",
        "\n",
        "# Compute scores & labels\n",
        "scores = np.array([\n",
        "    float(e1.dot(e2))\n",
        "    for e1, e2, _ in pairs\n",
        "])\n",
        "labels = np.array([lbl for *_, lbl in pairs])\n",
        "\n",
        "# 1. Predict labels at threshold\n",
        "predictions = (scores < threshold).astype(int)  # 1 = rejected, 0 = accepted\n",
        "\n",
        "# Count genuine and impostor errors directly using Boolean indexing\n",
        "genuine_errors = ((predictions == 1) & (labels == 0)).sum()  # 1 = rejected, 0 = accepted (genuine)\n",
        "imposter_errors = ((predictions == 0) & (labels == 1)).sum()  # 1 = rejected, 0 = accepted (impostor)\n",
        "\n",
        "# Count total genuine and impostor samples\n",
        "total_genuine = (labels == 0).sum()\n",
        "total_imposter = (labels == 1).sum()\n",
        "\n",
        "# Calculate rates\n",
        "FRR = (genuine_errors / total_genuine * 100) if total_genuine > 0 else 0\n",
        "FAR = (imposter_errors / total_imposter * 100) if total_imposter > 0 else 0\n",
        "\n",
        "print(f\"Threshold at: {threshold}\")\n",
        "print(f\"FRR: {FRR:.2f}%\")\n",
        "print(f\"FAR at {FAR:.2f}%\")"
      ],
      "metadata": {
        "id": "-1BFDPcnjdaP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculation of EER\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "# Compute scores & labels\n",
        "scores = np.array([\n",
        "    float(e1.dot(e2))\n",
        "    for e1, e2, _ in pairs\n",
        "])\n",
        "labels = np.array([lbl for *_, lbl in pairs])\n",
        "\n",
        "# Compute EER\n",
        "thresholds = np.linspace(scores.min(), scores.max(), 1000)\n",
        "best_diff = 1e9\n",
        "for threshold in thresholds:\n",
        "    predictions = (scores < threshold).astype(int)  # 1 = rejected, 0 = accepted\n",
        "\n",
        "    # Count genuine and impostor errors directly using Boolean indexing\n",
        "    genuine_errors = ((predictions == 1) & (labels == 0)).sum()  # 1 = rejected, 0 = accepted (genuine)\n",
        "    imposter_errors = ((predictions == 0) & (labels == 1)).sum()  # 1 = rejected, 0 = accepted (impostor)\n",
        "\n",
        "    # Count total genuine and impostor samples\n",
        "    total_genuine = (labels == 0).sum()\n",
        "    total_imposter = (labels == 1).sum()\n",
        "\n",
        "    # Calculate rates\n",
        "    FRR = (genuine_errors / total_genuine * 100) if total_genuine > 0 else 0\n",
        "    FAR = (imposter_errors / total_imposter * 100) if total_imposter > 0 else 0\n",
        "\n",
        "    # Calculate the absolute difference between FAR and FRR\n",
        "    diff = abs(FRR - FAR)\n",
        "\n",
        "    # Find the threshold that minimizes the difference\n",
        "    if diff < best_diff:\n",
        "        best_diff = diff\n",
        "        eer = (FRR + FAR) / 2\n",
        "        eer_threshold = threshold\n",
        "\n",
        "print(f\"EER ≈ {eer:.2f}% at threshold {eer_threshold:.4f}\")\n"
      ],
      "metadata": {
        "id": "1N4N4PSWHJOK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "# Compute FAR/FRR curves correctly and find EER\n",
        "\n",
        "# 1) Candidate thresholds\n",
        "ths = np.linspace(scores.min(), scores.max(), 1000)\n",
        "\n",
        "# 2) Compute curves\n",
        "FAR_curve = [(scores[labels==1] >= t).mean()*100 for t in ths]  # impostors accepted\n",
        "FRR_curve = [(scores[labels==0] <  t).mean()*100 for t in ths]  # genuines rejected\n",
        "\n",
        "# 3) Find EER\n",
        "diffs = np.abs(np.array(FAR_curve) - np.array(FRR_curve))\n",
        "idx   = diffs.argmin()\n",
        "eer   = (FAR_curve[idx] + FRR_curve[idx]) / 2\n",
        "eer_thr = ths[idx]\n",
        "\n",
        "print(f\"EER ≈ {eer:.2f}% at threshold {eer_thr:.4f}\")\n",
        "\n",
        "# 4) Plot\n",
        "plt.figure(figsize=(8,6))\n",
        "plt.plot(ths, FAR_curve, label='FAR')\n",
        "plt.plot(ths, FRR_curve, label='FRR')\n",
        "plt.scatter([eer_thr], [eer], s=80, c='blue', label=f'EER = {eer:.2f}%')\n",
        "plt.xlabel('Cosine Threshold')\n",
        "plt.ylabel('Error Rate (%)')\n",
        "plt.title('FAR and FRR vs Threshold')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "XpvgkFIDR6j2"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}